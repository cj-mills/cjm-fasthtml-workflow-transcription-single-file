"""File-based storage for transcription results"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/storage/file_storage.ipynb.

# %% auto 0
__all__ = ['ResultStorage']

# %% ../../nbs/storage/file_storage.ipynb 3
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
from fastcore.basics import patch

from .config import StorageConfig

# %% ../../nbs/storage/file_storage.ipynb 5
class ResultStorage:
    """File-based storage for transcription results.

    Each workflow instance gets its own storage instance with its own
    configuration, ensuring proper isolation between workflow instances.

    Results are stored as JSON files in the configured directory.
    """

    def __init__(self, config: StorageConfig):
        """Initialize the storage.

        Args:
            config: Storage configuration.
        """
        self.config = config
        self._results_dir: Optional[Path] = None

    @property
    def results_directory(self) -> Path:
        """Get the results directory, creating it if needed.

        Returns:
            Path to the results directory.
        """
        if self._results_dir is None:
            self._results_dir = Path(self.config.results_directory)
            self._results_dir.mkdir(exist_ok=True, parents=True)
        return self._results_dir

# %% ../../nbs/storage/file_storage.ipynb 6
@patch
def should_auto_save(self: ResultStorage) -> bool:
    """Check if auto-save is enabled.

    Returns:
        True if results should be automatically saved.
    """
    return self.config.auto_save

# %% ../../nbs/storage/file_storage.ipynb 7
@patch
def save(
    self: ResultStorage,
    job_id: str,
    file_path: str,
    file_name: str,
    plugin_id: str,
    plugin_name: str,
    text: str,
    metadata: Optional[Dict[str, Any]] = None,
    additional_info: Optional[Dict[str, Any]] = None
) -> Path:
    """Save a transcription result to JSON file.

    Args:
        job_id: Unique job identifier.
        file_path: Path to the transcribed media file.
        file_name: Name of the media file.
        plugin_id: Plugin unique identifier.
        plugin_name: Plugin display name.
        text: The transcription text.
        metadata: Optional metadata from the transcription plugin.
        additional_info: Optional additional information to store.

    Returns:
        Path to the saved JSON file.
    """
    # Create result data structure
    result_data = {
        "job_id": job_id,
        "timestamp": datetime.now().isoformat(),
        "file": {
            "path": file_path,
            "name": file_name
        },
        "plugin": {
            "id": plugin_id,
            "name": plugin_name
        },
        "transcription": {
            "text": text,
            "word_count": len(text.split()),
            "char_count": len(text)
        },
        "metadata": metadata or {},
        "additional_info": additional_info or {}
    }

    # Generate filename and save
    filename = self._generate_filename(job_id, file_name)
    result_path = self.results_directory / filename

    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)

    return result_path

# %% ../../nbs/storage/file_storage.ipynb 8
@patch
def load(self: ResultStorage, result_file: Path) -> Optional[Dict[str, Any]]:
    """Load a transcription result from JSON file.

    Args:
        result_file: Path to the JSON result file.

    Returns:
        Dictionary containing the result data, or None if error.
    """
    try:
        with open(result_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"[ResultStorage] Error loading result from {result_file}: {e}")
        return None

# %% ../../nbs/storage/file_storage.ipynb 9
@patch
def list_results(
    self: ResultStorage,
    sort_by: str = "timestamp",
    reverse: bool = True
) -> List[Dict[str, Any]]:
    """List all saved transcription results.

    Args:
        sort_by: Field to sort by ("timestamp", "file_name", "word_count").
        reverse: Sort in reverse order (newest first by default).

    Returns:
        List of result dictionaries.
    """
    results = []

    # Load all JSON files in the results directory
    for result_file in self.results_directory.glob("*.json"):
        result = self.load(result_file)
        if result:
            # Add filename for reference
            result["result_file"] = str(result_file)
            result["result_filename"] = result_file.name
            results.append(result)

    # Sort results
    sort_key_map = {
        "timestamp": lambda x: x.get("timestamp", ""),
        "file_name": lambda x: x.get("file", {}).get("name", ""),
        "word_count": lambda x: x.get("transcription", {}).get("word_count", 0)
    }

    if sort_by in sort_key_map:
        results.sort(key=sort_key_map[sort_by], reverse=reverse)

    return results

# %% ../../nbs/storage/file_storage.ipynb 10
@patch
def get_by_job_id(self: ResultStorage, job_id: str) -> Optional[Dict[str, Any]]:
    """Find and load a transcription result by job ID.

    Args:
        job_id: The job identifier to search for.

    Returns:
        Result dictionary if found, None otherwise.
    """
    results = self.list_results()

    for result in results:
        if result.get("job_id") == job_id:
            return result

    return None

# %% ../../nbs/storage/file_storage.ipynb 11
@patch
def delete(self: ResultStorage, result_file: str) -> bool:
    """Delete a transcription result file.

    Args:
        result_file: Path to the result file (can be full path or filename).

    Returns:
        True if deletion successful, False otherwise.
    """
    try:
        file_path = Path(result_file)

        # If only filename provided, look in results directory
        if not file_path.is_absolute():
            file_path = self.results_directory / file_path

        if file_path.exists():
            file_path.unlink()
            return True
        return False

    except Exception as e:
        print(f"[ResultStorage] Error deleting result file {result_file}: {e}")
        return False

# %% ../../nbs/storage/file_storage.ipynb 12
@patch
def update_text(self: ResultStorage, result_file: str, new_text: str) -> bool:
    """Update the transcription text in a saved result.

    Args:
        result_file: Path to the result file.
        new_text: New transcription text.

    Returns:
        True if update successful, False otherwise.
    """
    try:
        file_path = Path(result_file)

        # If only filename provided, look in results directory
        if not file_path.is_absolute():
            file_path = self.results_directory / file_path

        # Load existing result
        result = self.load(file_path)
        if not result:
            return False

        # Update transcription data
        result["transcription"]["text"] = new_text
        result["transcription"]["word_count"] = len(new_text.split())
        result["transcription"]["char_count"] = len(new_text)
        result["additional_info"]["last_edited"] = datetime.now().isoformat()

        # Save updated result
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        return True

    except Exception as e:
        print(f"[ResultStorage] Error updating result file {result_file}: {e}")
        return False

# %% ../../nbs/storage/file_storage.ipynb 13
@patch
def _generate_filename(self: ResultStorage, job_id: str, file_name: str) -> str:
    """Generate a filename for storing transcription results.

    Args:
        job_id: Unique job identifier.
        file_name: Original media file name.

    Returns:
        Generated filename for the JSON result file.
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # Sanitize file_name for use in filename
    safe_name = Path(file_name).stem.replace(" ", "_")[:50]
    return f"{timestamp}_{job_id[:8]}_{safe_name}.json"
