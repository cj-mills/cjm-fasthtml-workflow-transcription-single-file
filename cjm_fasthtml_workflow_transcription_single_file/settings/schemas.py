"""JSON schemas and utilities for workflow settings"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/settings/schemas.ipynb.

# %% auto 0
__all__ = ['SCHEMA_TITLE', 'SCHEMA_DESC', 'SCHEMA_MIN', 'SCHEMA_MAX', 'SCHEMA_ENUM', 'SCHEMA_MIN_LEN', 'SCHEMA_MAX_LEN',
           'SCHEMA_PATTERN', 'SCHEMA_FORMAT', 'WORKFLOW_SETTINGS_SCHEMA', 'WorkflowSettings', 'dataclass_to_jsonschema']

# %% ../../nbs/settings/schemas.ipynb 3
from dataclasses import dataclass, field, fields, MISSING
from typing import Dict, Any, List, Optional, get_type_hints, get_origin, get_args, ClassVar

from ..core.config import SingleFileWorkflowConfig
from ..media.config import MediaConfig
from ..storage.config import StorageConfig

# %% ../../nbs/settings/schemas.ipynb 5
# Schema metadata keys for field annotations
SCHEMA_TITLE = "title"        # Display title for the field
SCHEMA_DESC = "description"   # Help text description
SCHEMA_MIN = "minimum"        # Minimum value for numbers
SCHEMA_MAX = "maximum"        # Maximum value for numbers
SCHEMA_ENUM = "enum"          # Allowed values for dropdowns
SCHEMA_MIN_LEN = "minLength"  # Minimum string length
SCHEMA_MAX_LEN = "maxLength"  # Maximum string length
SCHEMA_PATTERN = "pattern"    # Regex pattern for strings
SCHEMA_FORMAT = "format"      # String format (email, uri, date, etc.)

# %% ../../nbs/settings/schemas.ipynb 7
@dataclass
class WorkflowSettings:
    """User-configurable settings for single-file transcription workflow."""
    
    # Class-level schema metadata (ClassVar excludes these from dataclass fields)
    __schema_name__: ClassVar[str] = "single_file_workflow"
    __schema_title__: ClassVar[str] = "Single File Transcription Settings"
    __schema_description__: ClassVar[str] = "Configure media scanning, storage, and workflow behavior"
    
    # Media settings (field names match MediaConfig for seamless config loading)
    directories: List[str] = field(
        default_factory=list,
        metadata={
            SCHEMA_TITLE: "Media Directories",
            SCHEMA_DESC: "Directories to scan for media files"
        }
    )
    scan_audio: bool = field(
        default=True,
        metadata={
            SCHEMA_TITLE: "Scan Audio Files",
            SCHEMA_DESC: "Include audio files in scan results"
        }
    )
    scan_video: bool = field(
        default=True,
        metadata={
            SCHEMA_TITLE: "Scan Video Files",
            SCHEMA_DESC: "Include video files in scan results"
        }
    )
    recursive_scan: bool = field(
        default=True,
        metadata={
            SCHEMA_TITLE: "Recursive Scan",
            SCHEMA_DESC: "Scan subdirectories"
        }
    )
    items_per_page: int = field(
        default=30,
        metadata={
            SCHEMA_TITLE: "Items Per Page",
            SCHEMA_DESC: "Number of files to show per page",
            SCHEMA_MIN: 10,
            SCHEMA_MAX: 100
        }
    )
    default_view: str = field(
        default="list",
        metadata={
            SCHEMA_TITLE: "Default View",
            SCHEMA_DESC: "Default view mode for file selection",
            SCHEMA_ENUM: ["list"]  # Currently only list view is implemented
        }
    )
    
    # Storage settings
    auto_save: bool = field(
        default=True,
        metadata={
            SCHEMA_TITLE: "Auto-save Results",
            SCHEMA_DESC: "Automatically save transcription results when complete"
        }
    )
    results_directory: str = field(
        default="transcription_results",
        metadata={
            SCHEMA_TITLE: "Results Directory",
            SCHEMA_DESC: "Directory to save transcription results"
        }
    )
    
    # Resource management settings
    gpu_memory_threshold_percent: float = field(
        default=45.0,
        metadata={
            SCHEMA_TITLE: "GPU Memory Threshold (%)",
            SCHEMA_DESC: "GPU memory usage threshold for conflict detection (0-100)",
            SCHEMA_MIN: 0,
            SCHEMA_MAX: 100
        }
    )

# %% ../../nbs/settings/schemas.ipynb 9
def _python_type_to_json_type(
    python_type: type  # Python type annotation to convert
) -> Dict[str, Any]:  # JSON schema type definition
    """Convert Python type to JSON schema type."""
    origin = get_origin(python_type)
    args = get_args(python_type)
    
    # Handle List[X] -> array with items
    if origin is list:
        item_type = args[0] if args else str
        return {
            "type": "array",
            "items": _python_type_to_json_type(item_type)
        }
    
    # Handle Optional[X] -> nullable type
    if origin is type(None) or (origin and type(None) in args):
        # Extract the non-None type
        non_none_types = [a for a in args if a is not type(None)]
        if non_none_types:
            base_schema = _python_type_to_json_type(non_none_types[0])
            base_schema["type"] = [base_schema["type"], "null"]
            return base_schema
        return {"type": "null"}
    
    # Handle basic types
    type_mapping = {
        str: {"type": "string"},
        int: {"type": "integer"},
        float: {"type": "number"},
        bool: {"type": "boolean"},
    }
    
    return type_mapping.get(python_type, {"type": "string"})

# %% ../../nbs/settings/schemas.ipynb 10
def dataclass_to_jsonschema(
    cls: type  # Dataclass with field metadata
) -> Dict[str, Any]:  # JSON schema dictionary
    """Convert a dataclass to a JSON schema for form generation."""
    if not hasattr(cls, "__dataclass_fields__"):
        raise TypeError(f"{cls} is not a dataclass")
    
    # Get class-level schema metadata
    schema = {
        "name": getattr(cls, "__schema_name__", cls.__name__),
        "title": getattr(cls, "__schema_title__", cls.__name__),
        "description": getattr(cls, "__schema_description__", cls.__doc__ or ""),
        "type": "object",
        "properties": {}
    }
    
    # Get type hints for the class
    try:
        type_hints = get_type_hints(cls)
    except Exception:
        type_hints = {}
    
    # Process each field
    for f in fields(cls):
        # Get Python type and convert to JSON schema type
        python_type = type_hints.get(f.name, str)
        prop_schema = _python_type_to_json_type(python_type)
        
        # Add metadata from field
        metadata = f.metadata or {}
        for key in [SCHEMA_TITLE, SCHEMA_DESC, SCHEMA_MIN, SCHEMA_MAX, 
                    SCHEMA_ENUM, SCHEMA_MIN_LEN, SCHEMA_MAX_LEN, 
                    SCHEMA_PATTERN, SCHEMA_FORMAT]:
            if key in metadata:
                prop_schema[key] = metadata[key]
        
        # Add default value (handle MISSING sentinel)
        if f.default is not MISSING:
            prop_schema["default"] = f.default
        elif f.default_factory is not MISSING:
            prop_schema["default"] = f.default_factory()
        
        schema["properties"][f.name] = prop_schema
    
    return schema

# %% ../../nbs/settings/schemas.ipynb 13
WORKFLOW_SETTINGS_SCHEMA = dataclass_to_jsonschema(WorkflowSettings) # Auto-generate schema from WorkflowSettings dataclass

# %% ../../nbs/settings/schemas.ipynb 15
from fastcore.basics import patch

# %% ../../nbs/settings/schemas.ipynb 16
@patch(cls_method=True)
def from_configs(
    cls: WorkflowSettings,
    media_config: MediaConfig,      # MediaConfig instance with media scanning settings
    storage_config: StorageConfig,  # StorageConfig instance with result storage settings
    workflow_config: Optional[SingleFileWorkflowConfig] = None  # Optional workflow config for additional settings
) -> "WorkflowSettings":  # WorkflowSettings instance with values from configs
    """Create WorkflowSettings from runtime config objects."""
    return cls(
        # Media settings
        directories=media_config.directories,
        scan_audio=media_config.scan_audio,
        scan_video=media_config.scan_video,
        recursive_scan=media_config.recursive_scan,
        items_per_page=media_config.items_per_page,
        default_view=media_config.default_view,
        # Storage settings
        auto_save=storage_config.auto_save,
        results_directory=storage_config.results_directory,
        # Workflow settings
        gpu_memory_threshold_percent=workflow_config.gpu_memory_threshold_percent if workflow_config else 45.0
    )

# %% ../../nbs/settings/schemas.ipynb 17
@patch
def apply_to_configs(
    self: WorkflowSettings,
    media_config: MediaConfig,      # MediaConfig instance to update
    storage_config: StorageConfig,  # StorageConfig instance to update
    workflow_config: Optional[SingleFileWorkflowConfig] = None  # Optional workflow config to update
) -> None:
    """Apply settings to runtime config objects."""
    # Media settings
    media_config.directories = self.directories
    media_config.scan_audio = self.scan_audio
    media_config.scan_video = self.scan_video
    media_config.recursive_scan = self.recursive_scan
    media_config.items_per_page = self.items_per_page
    media_config.default_view = self.default_view
    
    # Storage settings
    storage_config.auto_save = self.auto_save
    storage_config.results_directory = self.results_directory
    
    # Workflow settings
    if workflow_config:
        workflow_config.gpu_memory_threshold_percent = self.gpu_memory_threshold_percent

# %% ../../nbs/settings/schemas.ipynb 18
@patch
def to_dict(
    self: WorkflowSettings
) -> Dict[str, Any]:  # Dictionary of settings values
    """Convert settings to a dictionary for serialization."""
    return {
        "directories": self.directories,
        "scan_audio": self.scan_audio,
        "scan_video": self.scan_video,
        "recursive_scan": self.recursive_scan,
        "items_per_page": self.items_per_page,
        "default_view": self.default_view,
        "auto_save": self.auto_save,
        "results_directory": self.results_directory,
        "gpu_memory_threshold_percent": self.gpu_memory_threshold_percent,
    }
