{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84959352",
   "metadata": {},
   "source": [
    "# Job Handler\n",
    "\n",
    "> Functions for starting transcription jobs and handling SSE streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp workflow.job_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "from fasthtml.common import *\n",
    "\n",
    "from cjm_plugin_system.core.manager import PluginManager\n",
    "\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.config import SingleFileWorkflowConfig\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.html_ids import SingleFileHtmlIds\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.job_tracker import TranscriptionJob, TranscriptionJobTracker\n",
    "from cjm_fasthtml_workflow_transcription_single_file.components.processor import transcription_in_progress\n",
    "from cjm_fasthtml_workflow_transcription_single_file.components.results import transcription_results, transcription_error\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.protocols import PluginRegistryProtocol\n",
    "from cjm_fasthtml_workflow_transcription_single_file.storage.file_storage import ResultStorage\n",
    "from cjm_fasthtml_workflow_transcription_single_file.workflow.workflow import SingleFileTranscriptionWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72af9d-5368-40d5-918d-bebf5f317162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67ed9d-4035-45b9-86f1-7ad593f260cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_job_session_info(\n",
    "    job_id: str,  # Unique job identifier\n",
    "    job: TranscriptionJob,  # Job object from the tracker\n",
    "    plugin_manager: PluginManager,  # Plugin manager for getting plugin info\n",
    ") -> tuple[Dict[str, Any], Dict[str, Any]]:  # Tuple of (file_info, plugin_info) dictionaries\n",
    "    \"\"\"Get file and plugin info from job object and plugin manager.\"\"\"\n",
    "    # File info from job attributes\n",
    "    file_info = {\n",
    "        \"name\": job.file_name,\n",
    "        \"path\": job.file_path,\n",
    "    }\n",
    "\n",
    "    # Plugin info from plugin manager\n",
    "    plugin_meta = plugin_manager.get_plugin_meta(job.plugin_name)\n",
    "    plugin_info = {\n",
    "        \"id\": job.plugin_name,\n",
    "        \"title\": plugin_meta.name if plugin_meta else job.plugin_name,\n",
    "        \"supports_streaming\": False  # Could check from manifest if needed\n",
    "    }\n",
    "\n",
    "    return file_info, plugin_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0d2a2-b82f-4da9-9a3c-802896a5b021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334b3d5-14fb-49dc-9697-f600176ee466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _save_job_result_once(\n",
    "    job_id: str,  # Job identifier\n",
    "    job: TranscriptionJob,  # Job object\n",
    "    data: Dict[str, Any],  # Transcription data containing text and metadata\n",
    "    plugin_manager: PluginManager,  # Plugin manager for getting plugin info\n",
    "    result_storage: ResultStorage,  # Storage for saving transcription results\n",
    ") -> None:\n",
    "    \"\"\"Save transcription result to disk, ensuring it's only saved once per job.\n",
    "    \n",
    "    Called from the SSE stream handler as a fallback. The primary save mechanism\n",
    "    is the workflow's `_on_job_completed` callback called by TranscriptionJobTracker.\n",
    "    \"\"\"\n",
    "    # Skip if auto-save is disabled\n",
    "    if not result_storage.should_auto_save():\n",
    "        return\n",
    "\n",
    "    # Check if job metadata indicates it's already been saved\n",
    "    if job.metadata and job.metadata.get('saved_to_disk'):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Get file and plugin info from job and plugin manager\n",
    "        file_info, plugin_info = get_job_session_info(job_id, job, plugin_manager)\n",
    "\n",
    "        result_storage.save(\n",
    "            job_id=job_id,\n",
    "            file_path=file_info.get(\"path\", job.file_path),\n",
    "            file_name=file_info.get(\"name\", job.file_name),\n",
    "            plugin_id=plugin_info.get(\"id\", job.plugin_name),\n",
    "            plugin_name=plugin_info.get(\"title\", job.plugin_name),\n",
    "            text=data.get('text', ''),\n",
    "            metadata=data.get('metadata', {}),\n",
    "            additional_info={}\n",
    "        )\n",
    "\n",
    "        # Mark as saved in job metadata\n",
    "        if not job.metadata:\n",
    "            job.metadata = {}\n",
    "        job.metadata['saved_to_disk'] = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transcription result for job {job_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb921eb2-1071-4b5b-8a47-c0f8bb08457a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5f764-4f4f-42a4-b5c3-4d4db7af0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _create_sse_swap_message(\n",
    "    content,  # HTML content to wrap\n",
    "    container_id: str,  # Target container ID for the swap\n",
    "):  # Div with OOB swap attributes\n",
    "    \"\"\"Wrap content in a Div with HTMX OOB swap for SSE messages.\"\"\"\n",
    "    return Div(\n",
    "        content,\n",
    "        id=container_id,\n",
    "        hx_swap_oob=\"true\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d75131-4236-4b26-b298-cde156d16d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa9bd65",
   "metadata": {},
   "source": [
    "## start_transcription_job\n",
    "\n",
    "Starts a transcription job using the job manager and returns the in-progress UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def start_transcription_job(\n",
    "    state: Dict[str, Any],  # Workflow state containing plugin_id, file_path, file_name, etc.\n",
    "    request,  # FastHTML request object\n",
    "    workflow: SingleFileTranscriptionWorkflow,  # Workflow instance providing config and dependencies\n",
    "):  # transcription_in_progress component showing job status\n",
    "    \"\"\"Start a transcription job and return the in-progress UI component.\"\"\"\n",
    "    # Note: UI uses plugin_id, internal API uses plugin_name\n",
    "    plugin_name = state.get(\"plugin_id\")\n",
    "    file_path = state.get(\"file_path\")\n",
    "    file_name = state.get(\"file_name\")\n",
    "\n",
    "    # Create job in tracker\n",
    "    job = workflow.job_tracker.create_job(\n",
    "        plugin_name=plugin_name,\n",
    "        file_path=file_path,\n",
    "        file_name=file_name\n",
    "    )\n",
    "\n",
    "    # Define async execution function\n",
    "    async def execute_transcription():\n",
    "        workflow.job_tracker.mark_running(job.id)\n",
    "        try:\n",
    "            # Execute via PluginManager\n",
    "            result = await workflow.plugin_manager.execute_plugin_async(\n",
    "                plugin_name,\n",
    "                audio=file_path\n",
    "            )\n",
    "            # Convert result to dict if needed (e.g., if it's a dataclass)\n",
    "            if hasattr(result, '__dict__'):\n",
    "                result_dict = {\n",
    "                    \"text\": getattr(result, 'text', ''),\n",
    "                    \"confidence\": getattr(result, 'confidence', None),\n",
    "                    \"segments\": getattr(result, 'segments', []),\n",
    "                    \"metadata\": getattr(result, 'metadata', {})\n",
    "                }\n",
    "            elif isinstance(result, dict):\n",
    "                result_dict = result\n",
    "            else:\n",
    "                result_dict = {\"text\": str(result), \"metadata\": {}}\n",
    "                \n",
    "            workflow.job_tracker.mark_completed(job.id, result_dict)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            workflow.job_tracker.mark_failed(job.id, str(e))\n",
    "\n",
    "    # Create and store the async task for cancellation support\n",
    "    task = asyncio.create_task(execute_transcription())\n",
    "    workflow.job_tracker.mark_running(job.id, task)\n",
    "\n",
    "    # Get plugin info for display\n",
    "    plugin_meta = workflow.plugin_manager.get_plugin_meta(plugin_name)\n",
    "\n",
    "    file_info = {\n",
    "        \"name\": file_name,\n",
    "        \"path\": file_path,\n",
    "        \"type\": state.get(\"file_type\", \"unknown\"),\n",
    "        \"size_str\": state.get(\"file_size\", \"unknown\")\n",
    "    }\n",
    "\n",
    "    plugin_info = {\n",
    "        \"id\": plugin_name,\n",
    "        \"title\": plugin_meta.name if plugin_meta else plugin_name,\n",
    "        \"supports_streaming\": False\n",
    "    }\n",
    "\n",
    "    # Return in-progress view\n",
    "    return transcription_in_progress(\n",
    "        job_id=job.id,\n",
    "        plugin_info=plugin_info,\n",
    "        file_info=file_info,\n",
    "        config=workflow.config,\n",
    "        router=workflow.router,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f579956",
   "metadata": {},
   "source": [
    "## create_job_stream_handler\n",
    "\n",
    "Creates an async generator for SSE streaming of transcription progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_job_stream_handler(\n",
    "    job_id: str,  # Unique job identifier\n",
    "    request,  # FastHTML request object\n",
    "    workflow: SingleFileTranscriptionWorkflow,  # Workflow instance providing config and dependencies\n",
    "):  # Async generator for SSE streaming\n",
    "    \"\"\"Create an SSE stream generator for monitoring job completion.\"\"\"\n",
    "    poll_interval = workflow.config.sse_poll_interval\n",
    "    container_id = workflow.config.container_id\n",
    "    # Build URL using router's .to() method for proper route generation\n",
    "    stepflow_start_url = workflow.stepflow_router.start.to()\n",
    "\n",
    "    async def job_stream():\n",
    "        try:\n",
    "            # Check if job exists\n",
    "            job = workflow.job_tracker.get_job(job_id)\n",
    "            if not job:\n",
    "                yield sse_message(Div(\"Job not found\"))\n",
    "                return\n",
    "\n",
    "            # Poll for completion\n",
    "            while True:\n",
    "                job = workflow.job_tracker.get_job(job_id)\n",
    "                if not job:\n",
    "                    break\n",
    "\n",
    "                # Check if job finished\n",
    "                if job.status in ['completed', 'failed', 'cancelled']:\n",
    "                    result = workflow.job_tracker.get_job_result(job_id)\n",
    "\n",
    "                    if job.status == 'completed' and result and result.get('status') == 'success':\n",
    "                        data = result.get('data', {})\n",
    "                        file_info, plugin_info = get_job_session_info(job_id, job, workflow.plugin_manager)\n",
    "\n",
    "                        # Save result to disk (only once)\n",
    "                        _save_job_result_once(job_id, job, data, workflow.plugin_manager, workflow.result_storage)\n",
    "\n",
    "                        results = transcription_results(\n",
    "                            job_id=job_id,\n",
    "                            transcription_text=data.get('text', ''),\n",
    "                            metadata=data.get('metadata', {}),\n",
    "                            file_info=file_info,\n",
    "                            plugin_info=plugin_info,\n",
    "                            config=workflow.config,\n",
    "                            router=workflow.router,\n",
    "                            stepflow_router=workflow.stepflow_router,\n",
    "                        )\n",
    "\n",
    "                        yield sse_message(_create_sse_swap_message(results, container_id))\n",
    "\n",
    "                    elif job.status == 'failed':\n",
    "                        file_info, _ = get_job_session_info(job_id, job, workflow.plugin_manager)\n",
    "                        error_msg = transcription_error(\n",
    "                            f\"Transcription failed: {job.error}\",\n",
    "                            file_info,\n",
    "                            config=workflow.config,\n",
    "                            stepflow_router=workflow.stepflow_router,\n",
    "                        )\n",
    "                        yield sse_message(_create_sse_swap_message(error_msg, container_id))\n",
    "\n",
    "                    elif job.status == 'cancelled':\n",
    "                        # Return a message that triggers reload of the start view\n",
    "                        redirect_div = Div(\n",
    "                            Script(f\"\"\"\n",
    "                                htmx.ajax('GET', '{stepflow_start_url}', {{\n",
    "                                    target: '#{container_id}',\n",
    "                                    swap: 'innerHTML'\n",
    "                                }});\n",
    "                            \"\"\"),\n",
    "                            id=container_id,\n",
    "                            hx_swap_oob=\"true\"\n",
    "                        )\n",
    "                        yield sse_message(redirect_div)\n",
    "\n",
    "                    break\n",
    "\n",
    "                # Heartbeat\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                yield \": heartbeat\\n\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in job stream for {job_id}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return job_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d7f00-78ae-4440-8328-c008a668d940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082f5c6-a62d-49dd-8e1b-2b268f9850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09958823-a772-4d57-9ec8-fb1543aa8584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb6c7e-e097-4fe3-a2c1-71e475a84f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
