{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84959352",
   "metadata": {},
   "source": [
    "# Job Handler\n",
    "\n",
    "> Functions for starting transcription jobs and handling SSE streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp workflow.job_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "from fasthtml.common import *\n",
    "\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.config import SingleFileWorkflowConfig\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.html_ids import SingleFileHtmlIds\n",
    "from cjm_fasthtml_workflow_transcription_single_file.components.processor import transcription_in_progress\n",
    "from cjm_fasthtml_workflow_transcription_single_file.components.results import transcription_results, transcription_error\n",
    "from cjm_fasthtml_workflow_transcription_single_file.core.protocols import PluginRegistryProtocol\n",
    "from cjm_fasthtml_workflow_transcription_single_file.storage.file_storage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72af9d-5368-40d5-918d-bebf5f317162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67ed9d-4035-45b9-86f1-7ad593f260cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_job_session_info(\n",
    "    job_id: str,  # Unique job identifier\n",
    "    job,  # Job object from the manager\n",
    "    plugin_registry: PluginRegistryProtocol,  # Plugin registry for getting plugin info\n",
    ") -> tuple[Dict[str, Any], Dict[str, Any]]:  # Tuple of (file_info, plugin_info) dictionaries\n",
    "    \"\"\"Get file and plugin info from job object and plugin registry.\"\"\"\n",
    "    # File info from job attributes\n",
    "    file_info = {\n",
    "        \"name\": getattr(job, \"file_name\", \"unknown\"),\n",
    "        \"path\": getattr(job, \"file_path\", \"\"),\n",
    "    }\n",
    "\n",
    "    # Plugin info from registry\n",
    "    plugin_id = getattr(job, \"plugin_id\", \"unknown\")\n",
    "    plugin_obj = plugin_registry.get_plugin(plugin_id)\n",
    "    plugin_info = {\n",
    "        \"id\": plugin_id,\n",
    "        \"title\": plugin_obj.title if plugin_obj else plugin_id,\n",
    "        \"supports_streaming\": plugin_obj.supports_streaming if plugin_obj else False\n",
    "    }\n",
    "\n",
    "    return file_info, plugin_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0d2a2-b82f-4da9-9a3c-802896a5b021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334b3d5-14fb-49dc-9697-f600176ee466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _save_job_result_once(\n",
    "    job_id: str,  # Job identifier\n",
    "    job,  # Job object\n",
    "    data: Dict[str, Any],  # Transcription data containing text and metadata\n",
    "    plugin_registry: PluginRegistryProtocol,  # Plugin registry for getting plugin info\n",
    "    result_storage: ResultStorage,  # Storage for saving transcription results\n",
    ") -> None:\n",
    "    \"\"\"Save transcription result to disk, ensuring it's only saved once per job.\n",
    "    \n",
    "    Called from the SSE stream handler as a fallback. The primary save mechanism\n",
    "    is the workflow's `_on_job_completed` callback called by TranscriptionJobManager.\n",
    "    \"\"\"\n",
    "    # Skip if auto-save is disabled\n",
    "    if not result_storage.should_auto_save():\n",
    "        return\n",
    "\n",
    "    # Check if job metadata indicates it's already been saved\n",
    "    if hasattr(job, 'metadata') and job.metadata and job.metadata.get('saved_to_disk'):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Get file and plugin info from job attributes and registry\n",
    "        file_info, plugin_info = get_job_session_info(job_id, job, plugin_registry)\n",
    "\n",
    "        result_storage.save(\n",
    "            job_id=job_id,\n",
    "            file_path=file_info.get(\"path\", getattr(job, \"file_path\", \"\")),\n",
    "            file_name=file_info.get(\"name\", getattr(job, \"file_name\", \"\")),\n",
    "            plugin_id=plugin_info.get(\"id\", getattr(job, \"plugin_id\", \"\")),\n",
    "            plugin_name=plugin_info.get(\"title\", getattr(job, \"plugin_id\", \"\")),\n",
    "            text=data.get('text', ''),\n",
    "            metadata=data.get('metadata', {}),\n",
    "            additional_info={}\n",
    "        )\n",
    "\n",
    "        # Mark as saved in job metadata\n",
    "        if not job.metadata:\n",
    "            job.metadata = {}\n",
    "        job.metadata['saved_to_disk'] = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving transcription result for job {job_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb921eb2-1071-4b5b-8a47-c0f8bb08457a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5f764-4f4f-42a4-b5c3-4d4db7af0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _create_sse_swap_message(\n",
    "    content,  # HTML content to wrap\n",
    "    container_id: str,  # Target container ID for the swap\n",
    "):  # Div with OOB swap attributes\n",
    "    \"\"\"Wrap content in a Div with HTMX OOB swap for SSE messages.\"\"\"\n",
    "    return Div(\n",
    "        content,\n",
    "        id=container_id,\n",
    "        hx_swap_oob=\"true\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d75131-4236-4b26-b298-cde156d16d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa9bd65",
   "metadata": {},
   "source": [
    "## start_transcription_job\n",
    "\n",
    "Starts a transcription job using the job manager and returns the in-progress UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def start_transcription_job(\n",
    "    state: Dict[str, Any],  # Workflow state containing plugin_id, file_path, file_name, etc.\n",
    "    request,  # FastHTML request object\n",
    "    config: SingleFileWorkflowConfig,  # Workflow configuration\n",
    "    router,  # Workflow router for generating route URLs\n",
    "    transcription_manager,  # Manager for starting transcription jobs\n",
    "    plugin_registry: PluginRegistryProtocol,  # Plugin registry for getting plugin info\n",
    "):  # transcription_in_progress component showing job status\n",
    "    \"\"\"Handle workflow completion by starting the transcription job.\n",
    "    \n",
    "    Called by StepFlow's `on_complete` handler when the user confirms\n",
    "    and clicks \"Start Transcription\".\n",
    "    \"\"\"\n",
    "    plugin_id = state.get(\"plugin_id\")\n",
    "    file_path = state.get(\"file_path\")\n",
    "    file_name = state.get(\"file_name\")\n",
    "\n",
    "    # Start the transcription job via the internal manager\n",
    "    job = await transcription_manager.start_transcription(\n",
    "        plugin_id=plugin_id,\n",
    "        file_path=file_path,\n",
    "        file_name=file_name\n",
    "    )\n",
    "\n",
    "    # Get plugin info for display\n",
    "    plugin_info_obj = plugin_registry.get_plugin(plugin_id)\n",
    "\n",
    "    file_info = {\n",
    "        \"name\": file_name,\n",
    "        \"path\": file_path,\n",
    "        \"type\": state.get(\"file_type\", \"unknown\"),\n",
    "        \"size_str\": state.get(\"file_size\", \"unknown\")\n",
    "    }\n",
    "\n",
    "    plugin_info = {\n",
    "        \"id\": plugin_id,\n",
    "        \"title\": plugin_info_obj.title if plugin_info_obj else plugin_id,\n",
    "        \"supports_streaming\": plugin_info_obj.supports_streaming if plugin_info_obj else False\n",
    "    }\n",
    "\n",
    "    # Note: Workflow state is cleared by the workflow's on_complete handler\n",
    "    # after this function returns, via state_store.clear_state()\n",
    "\n",
    "    # Return in-progress view\n",
    "    return transcription_in_progress(\n",
    "        job_id=job.id,\n",
    "        plugin_info=plugin_info,\n",
    "        file_info=file_info,\n",
    "        config=config,\n",
    "        router=router,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f579956",
   "metadata": {},
   "source": [
    "## create_job_stream_handler\n",
    "\n",
    "Creates an async generator for SSE streaming of transcription progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_job_stream_handler(\n",
    "    job_id: str,  # Unique job identifier\n",
    "    request,  # FastHTML request object\n",
    "    config: SingleFileWorkflowConfig,  # Workflow configuration\n",
    "    router,  # Workflow router for generating route URLs\n",
    "    stepflow_router: APIRouter,  # StepFlow router for generating stepflow URLs\n",
    "    transcription_manager,  # Manager for getting job status\n",
    "    plugin_registry: PluginRegistryProtocol,  # Plugin registry for getting plugin info\n",
    "    result_storage: ResultStorage,  # Storage for saving transcription results\n",
    "):  # Async generator for SSE streaming\n",
    "    \"\"\"Create an SSE stream generator for monitoring job completion.\"\"\"\n",
    "    poll_interval = config.sse_poll_interval\n",
    "    container_id = config.container_id\n",
    "    # Build URL using router's .to() method for proper route generation\n",
    "    stepflow_start_url = stepflow_router.start.to()\n",
    "\n",
    "    async def job_stream():\n",
    "        try:\n",
    "            # Check if job exists\n",
    "            job = transcription_manager.get_job(job_id)\n",
    "            if not job:\n",
    "                yield sse_message(Div(\"Job not found\"))\n",
    "                return\n",
    "\n",
    "            # Poll for completion\n",
    "            while True:\n",
    "                job = transcription_manager.get_job(job_id)\n",
    "                if not job:\n",
    "                    break\n",
    "\n",
    "                # Check if job finished\n",
    "                if job.status in ['completed', 'failed', 'cancelled']:\n",
    "                    result = transcription_manager.get_job_result(job_id)\n",
    "\n",
    "                    if job.status == 'completed' and result and result.get('status') == 'success':\n",
    "                        data = result.get('data', {})\n",
    "                        file_info, plugin_info = get_job_session_info(job_id, job, plugin_registry)\n",
    "\n",
    "                        # Save result to disk (only once)\n",
    "                        _save_job_result_once(job_id, job, data, plugin_registry, result_storage)\n",
    "\n",
    "                        results = transcription_results(\n",
    "                            job_id=job_id,\n",
    "                            transcription_text=data.get('text', ''),\n",
    "                            metadata=data.get('metadata', {}),\n",
    "                            file_info=file_info,\n",
    "                            plugin_info=plugin_info,\n",
    "                            config=config,\n",
    "                            router=router,\n",
    "                            stepflow_router=stepflow_router,\n",
    "                        )\n",
    "\n",
    "                        yield sse_message(_create_sse_swap_message(results, container_id))\n",
    "\n",
    "                    elif job.status == 'failed':\n",
    "                        file_info, _ = get_job_session_info(job_id, job, plugin_registry)\n",
    "                        error_msg = transcription_error(\n",
    "                            f\"Transcription failed: {job.error}\",\n",
    "                            file_info,\n",
    "                            config=config,\n",
    "                            stepflow_router=stepflow_router,\n",
    "                        )\n",
    "                        yield sse_message(_create_sse_swap_message(error_msg, container_id))\n",
    "\n",
    "                    elif job.status == 'cancelled':\n",
    "                        # Return a message that triggers reload of the start view\n",
    "                        # We can't call stepflow_router.start directly, so we use a redirect approach\n",
    "                        redirect_div = Div(\n",
    "                            Script(f\"\"\"\n",
    "                                htmx.ajax('GET', '{stepflow_start_url}', {{\n",
    "                                    target: '#{container_id}',\n",
    "                                    swap: 'innerHTML'\n",
    "                                }});\n",
    "                            \"\"\"),\n",
    "                            id=container_id,\n",
    "                            hx_swap_oob=\"true\"\n",
    "                        )\n",
    "                        yield sse_message(redirect_div)\n",
    "\n",
    "                    break\n",
    "\n",
    "                # Heartbeat\n",
    "                await asyncio.sleep(poll_interval)\n",
    "                yield \": heartbeat\\n\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in job stream for {job_id}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return job_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d7f00-78ae-4440-8328-c008a668d940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082f5c6-a62d-49dd-8e1b-2b268f9850eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09958823-a772-4d57-9ec8-fb1543aa8584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb6c7e-e097-4fe3-a2c1-71e475a84f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
