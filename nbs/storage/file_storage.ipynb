{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e53feb97",
   "metadata": {},
   "source": [
    "# Result Storage\n",
    "\n",
    "> File-based storage for transcription results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp storage.file_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4183564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional, List\n",
    "from fastcore.basics import patch\n",
    "\n",
    "from cjm_fasthtml_workflow_transcription_single_file.storage.config import StorageConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8c5f3",
   "metadata": {},
   "source": [
    "## ResultStorage Class\n",
    "\n",
    "Handles saving and loading transcription results to/from JSON files. Organizes results by date with metadata for easy retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13880b8d",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nclass ResultStorage:\n    \"\"\"File-based storage for transcription results.\"\"\"\n\n    def __init__(self,\n                 config: StorageConfig  # Storage configuration\n                 ):\n        \"\"\"Initialize the storage.\"\"\"\n        self.config = config\n        self._results_dir: Optional[Path] = None\n\n    @property\n    def results_directory(self) -> Path:  # Path to the results directory\n        \"\"\"Get the results directory, creating it if needed.\"\"\"\n        if self._results_dir is None:\n            self._results_dir = Path(self.config.results_directory)\n            self._results_dir.mkdir(exist_ok=True, parents=True)\n        return self._results_dir"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9236392-9287-4886-94fd-0527ad99921a",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef should_auto_save(\n    self: ResultStorage\n) -> bool:  # True if results should be automatically saved\n    \"\"\"Check if auto-save is enabled.\"\"\"\n    return self.config.auto_save"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f3873-37e3-439d-a5fc-f4941b5bc777",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef save(\n    self: ResultStorage,\n    job_id: str,  # Unique job identifier\n    file_path: str,  # Path to the transcribed media file\n    file_name: str,  # Name of the media file\n    plugin_id: str,  # Plugin unique identifier\n    plugin_name: str,  # Plugin display name\n    text: str,  # The transcription text\n    metadata: Optional[Dict[str, Any]] = None,  # Optional metadata from the transcription plugin\n    additional_info: Optional[Dict[str, Any]] = None  # Optional additional information to store\n) -> Path:  # Path to the saved JSON file\n    \"\"\"Save a transcription result to JSON file.\"\"\"\n    # Create result data structure\n    result_data = {\n        \"job_id\": job_id,\n        \"timestamp\": datetime.now().isoformat(),\n        \"file\": {\n            \"path\": file_path,\n            \"name\": file_name\n        },\n        \"plugin\": {\n            \"id\": plugin_id,\n            \"name\": plugin_name\n        },\n        \"transcription\": {\n            \"text\": text,\n            \"word_count\": len(text.split()),\n            \"char_count\": len(text)\n        },\n        \"metadata\": metadata or {},\n        \"additional_info\": additional_info or {}\n    }\n\n    # Generate filename and save\n    filename = self._generate_filename(job_id, file_name)\n    result_path = self.results_directory / filename\n\n    with open(result_path, 'w', encoding='utf-8') as f:\n        json.dump(result_data, f, indent=2, ensure_ascii=False)\n\n    return result_path"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfc748-0ef8-4140-9711-b78ea9ec6b93",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef load(\n    self: ResultStorage,\n    result_file: Path  # Path to the JSON result file\n) -> Optional[Dict[str, Any]]:  # Dictionary containing the result data, or None if error\n    \"\"\"Load a transcription result from JSON file.\"\"\"\n    try:\n        with open(result_file, 'r', encoding='utf-8') as f:\n            return json.load(f)\n    except Exception as e:\n        print(f\"[ResultStorage] Error loading result from {result_file}: {e}\")\n        return None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e13bed-9da5-4559-ae56-b9b2d7a9dbe2",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef list_results(\n    self: ResultStorage,\n    sort_by: str = \"timestamp\",  # Field to sort by (\"timestamp\", \"file_name\", \"word_count\")\n    reverse: bool = True  # Sort in reverse order (newest first by default)\n) -> List[Dict[str, Any]]:  # List of result dictionaries\n    \"\"\"List all saved transcription results.\"\"\"\n    results = []\n\n    # Load all JSON files in the results directory\n    for result_file in self.results_directory.glob(\"*.json\"):\n        result = self.load(result_file)\n        if result:\n            # Add filename for reference\n            result[\"result_file\"] = str(result_file)\n            result[\"result_filename\"] = result_file.name\n            results.append(result)\n\n    # Sort results\n    sort_key_map = {\n        \"timestamp\": lambda x: x.get(\"timestamp\", \"\"),\n        \"file_name\": lambda x: x.get(\"file\", {}).get(\"name\", \"\"),\n        \"word_count\": lambda x: x.get(\"transcription\", {}).get(\"word_count\", 0)\n    }\n\n    if sort_by in sort_key_map:\n        results.sort(key=sort_key_map[sort_by], reverse=reverse)\n\n    return results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ede6f4-233c-4e67-bff5-dc831ea125fc",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef get_by_job_id(\n    self: ResultStorage,\n    job_id: str  # The job identifier to search for\n) -> Optional[Dict[str, Any]]:  # Result dictionary if found, None otherwise\n    \"\"\"Find and load a transcription result by job ID.\"\"\"\n    results = self.list_results()\n\n    for result in results:\n        if result.get(\"job_id\") == job_id:\n            return result\n\n    return None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917dd1b-2ea5-40d4-aed5-699b06681b3c",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef delete(\n    self: ResultStorage,\n    result_file: str  # Path to the result file (can be full path or filename)\n) -> bool:  # True if deletion successful, False otherwise\n    \"\"\"Delete a transcription result file.\"\"\"\n    try:\n        file_path = Path(result_file)\n\n        # If only filename provided, look in results directory\n        if not file_path.is_absolute():\n            file_path = self.results_directory / file_path\n\n        if file_path.exists():\n            file_path.unlink()\n            return True\n        return False\n\n    except Exception as e:\n        print(f\"[ResultStorage] Error deleting result file {result_file}: {e}\")\n        return False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba45aa-8680-4f8d-b05b-eb9205bef130",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef update_text(\n    self: ResultStorage,\n    result_file: str,  # Path to the result file\n    new_text: str  # New transcription text\n) -> bool:  # True if update successful, False otherwise\n    \"\"\"Update the transcription text in a saved result.\"\"\"\n    try:\n        file_path = Path(result_file)\n\n        # If only filename provided, look in results directory\n        if not file_path.is_absolute():\n            file_path = self.results_directory / file_path\n\n        # Load existing result\n        result = self.load(file_path)\n        if not result:\n            return False\n\n        # Update transcription data\n        result[\"transcription\"][\"text\"] = new_text\n        result[\"transcription\"][\"word_count\"] = len(new_text.split())\n        result[\"transcription\"][\"char_count\"] = len(new_text)\n        result[\"additional_info\"][\"last_edited\"] = datetime.now().isoformat()\n\n        # Save updated result\n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump(result, f, indent=2, ensure_ascii=False)\n\n        return True\n\n    except Exception as e:\n        print(f\"[ResultStorage] Error updating result file {result_file}: {e}\")\n        return False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c85b1-cef8-4384-aa51-b1869471d40f",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _generate_filename(\n    self: ResultStorage,\n    job_id: str,  # Unique job identifier\n    file_name: str  # Original media file name\n) -> str:  # Generated filename for the JSON result file\n    \"\"\"Generate a filename for storing transcription results.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    # Sanitize file_name for use in filename\n    safe_name = Path(file_name).stem.replace(\" \", \"_\")[:50]\n    return f\"{timestamp}_{job_id[:8]}_{safe_name}.json\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6272132-d158-4d85-a611-265090e26b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275d92e-bbf8-4891-8806-ce1275ebf5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5663c3",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acd34b-9855-492d-89c2-c33e255f98d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583a350-06f0-41f0-952e-065df36831af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa224b3e-63ca-4d4d-aaf3-e45982a761d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae372c65-a443-4f23-8dd9-d797b79fcc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaccff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
